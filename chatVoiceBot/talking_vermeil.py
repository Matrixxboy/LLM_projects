import torch
import sounddevice as sd
import requests
import textwrap
import speech_recognition as sr
from TTS.api import TTS

# ğŸ§  OLLAMA Config
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "vermeil" # You can also use mistral, llama3, etc.

# ğŸ¤ Load the TTS model
tts = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC", progress_bar=False, gpu=torch.cuda.is_available())

# ğŸ™ï¸ Setup speech recognizer
recognizer = sr.Recognizer()
mic = sr.Microphone()

# ğŸ” Conversation loop
while True:
    try:
        print("\nğŸ¤ Speak now (or say 'quit' to exit)...")
        with mic as source:
            recognizer.adjust_for_ambient_noise(source)
            audio_input = recognizer.listen(source)

        # ğŸ”Š Convert speech to text
        user_prompt = recognizer.recognize_google(audio_input)
        print(f"\nğŸ§‘ You said: {user_prompt}")

        # ğŸ”š Exit if needed
        if user_prompt.lower() in ['exit', 'quit']:
            print("ğŸ‘‹ Goodbye.")
            break

        # ğŸ§  Generate response from Ollama
        response = requests.post(
            OLLAMA_URL,
            json={"model": OLLAMA_MODEL, "prompt": user_prompt, "stream": False}
        )
        reply = response.json().get("response", "").strip()

        # ğŸ’¬ Print and speak
        print("\nğŸ¤– Vermeil:\n", textwrap.fill(reply, width=80))
        audio = tts.tts(reply)
        sd.play(audio, samplerate=tts.synthesizer.output_sample_rate)
        sd.wait()

    except sr.UnknownValueError:
        print("âš ï¸ Could not understand your voice. Please try again.")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Exiting gracefully.")
        break
    except Exception as e:
        print("âš ï¸ Error:", e)
